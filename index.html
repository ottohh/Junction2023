<!doctype html>

<html>
  <head>
    <meta charset="utf-8">
    <title>WebGPU Life</title>
  </head>
  <body>
    <canvas width="512" height="512"></canvas>
    <script type="module">
				const adapter = await navigator.gpu?.requestAdapter();
				const device = await adapter?.requestDevice();
				if (!device) {
					throw new Error()
				}

				// Get a WebGPU context from the canvas and configure it
				const canvas = document.querySelector('canvas');
				const context = canvas.getContext('webgpu');
				const canvasFormat = navigator.gpu.getPreferredCanvasFormat();
				context.configure({
					device: device,
					format: canvasFormat,
				})
				const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
				context.configure({
					device,
					format: presentationFormat,
				});
				/*
				const vertices = new Float32Array([
				//   X,    Y,
					-0.8, -0.8, // Triangle 1 (Blue)
					0.8, -0.8,
					0.8,  0.8,

					-0.8, -0.8, // Triangle 2 (Red)
					0.8,  0.8,
					-0.8,  0.8,
				]);*/

				const SUBDIVISIONS = 100;
				const vertices = new Float32Array(SUBDIVISIONS*6)
				for(let i = 0; i < SUBDIVISIONS; i++){
					vertices[6*i] = 0;
					vertices[6*i+1] = 0;
					vertices[6*i+2] = Math.cos(2*Math.PI/SUBDIVISIONS*i);
					vertices[6*i+3] = Math.sin(2*Math.PI/SUBDIVISIONS*i);
					vertices[6*i+4] = Math.cos(2*Math.PI/SUBDIVISIONS*(i+1));
					vertices[6*i+5] = Math.sin(2*Math.PI/SUBDIVISIONS*(i+1));
				}

				const vertexBuffer = device.createBuffer({
				label: "Cell vertices",
				size: vertices.byteLength,
				usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
			});
			device.queue.writeBuffer(vertexBuffer, /*bufferOffset=*/0, vertices);
				
			const vertexBufferLayout = {
				arrayStride: 8,
				attributes: [{
					format: "float32x2",
					offset: 0,
					shaderLocation: 0, // Position, see vertex shader
				}],
			};
			const cellShaderModule = device.createShaderModule({
					label: 'Cell shader',
					code: `
					struct VertexInput {
					@location(0) pos: vec2f
				};

				struct VertexOutput {
					@builtin(position) pos: vec4f,
				};
				struct FragInput {
					@builtin(position) pos: vec4f,
				};
						@vertex
						fn vertexMain(input: VertexInput) -> VertexOutput  {
							
							var output: VertexOutput;
  						output.pos = vec4f(input.pos, 0, 1);;
							return output;
						}

						@fragment
						fn fragmentMain(input: FragInput) -> @location(0) vec4f {
							return vec4f(input.pos.x/500, input.pos.y/500, 0, 1);
						}
					`
				});



				const cellPipeline = device.createRenderPipeline({
					label: "Cell pipeline",
					layout: "auto",
					vertex: {
						module: cellShaderModule,
						entryPoint: "vertexMain",
						buffers: [vertexBufferLayout]
					},
					fragment: {
						module: cellShaderModule,
						entryPoint: "fragmentMain",
						targets: [{
							format: canvasFormat
						}]
					}
				});

				const encoder = device.createCommandEncoder();
				const pass = encoder.beginRenderPass({
  colorAttachments: [{
     view: context.getCurrentTexture().createView(),
     loadOp: "clear",
     storeOp: "store",
  }]
});
				pass.setPipeline(cellPipeline);
				pass.setVertexBuffer(0, vertexBuffer);
				pass.draw(vertices.length / 2); // 6 vertices
				pass.end()
				device.queue.submit([encoder.finish()]);
  
    </script>
  </body>
</html>